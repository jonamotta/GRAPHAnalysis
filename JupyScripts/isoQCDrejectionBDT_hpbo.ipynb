{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization of XGBoost hyperparameters for the ISO and QCD rejection BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.lines as mlines\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import btdtri # beta quantile function\n",
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indir = '/home/llr/cms/motta/HGCAL/CMSSW_11_1_0/src/GRAPHAnalysis/L1BDT/hdf5dataframes/isolated'\n",
    "\n",
    "FE = 'threshold'\n",
    "\n",
    "inFileTraining_dict = {\n",
    "    'threshold'    : indir+'/Training_PU200_th_isoCalculated.hdf5',\n",
    "    'mixed'        : indir+'/'\n",
    "}\n",
    "\n",
    "# features for BDT training\n",
    "features = ['cl3d_pt_c1', 'cl3d_pt_c2', 'cl3d_pt_c3', 'cl3d_abseta', 'cl3d_showerlength', 'cl3d_coreshowerlength', 'cl3d_firstlayer', 'cl3d_maxlayer', 'cl3d_szz', 'cl3d_seetot', 'cl3d_spptot', 'cl3d_srrtot', 'cl3d_srrmean', 'cl3d_hoe', 'cl3d_meanz', 'cl3d_layer10', 'cl3d_layer50', 'cl3d_layer90', 'cl3d_ntc67', 'cl3d_ntc90', 'cl3d_NclIso_dR4', 'cl3d_etIso_dR4', 'tower_etSgn_dRsgn1', 'tower_eSgn_dRsgn1', 'tower_etSgn_dRsgn2', 'tower_eSgn_dRsgn2', 'tower_etIso_dRsgn1_dRiso3', 'tower_eIso_dRsgn1_dRiso3', 'tower_etEmIso_dRsgn1_dRiso3', 'tower_etHadIso_dRsgn1_dRiso7', 'tower_etIso_dRsgn2_dRiso4', 'tower_eIso_dRsgn2_dRiso4', 'tower_etEmIso_dRsgn2_dRiso4', 'tower_etHadIso_dRsgn2_dRiso7']\n",
    "output = 'iso_pid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_tr = pd.HDFStore(inFileTraining_dict[FE], mode='r')\n",
    "dfTraining = store_tr[FE]\n",
    "store_tr.close()\n",
    "\n",
    "dfTraining_dict[name]['iso_pid'] = dfTraining_dict[name]['gentau_decayMode'].copy(deep=True)\n",
    "dfTraining_dict[name]['iso_pid'].replace([0,1,10,11], 1, inplace=True)\n",
    "dfTraining_dict[name]['iso_pid'].replace([-2,-1], 0, inplace=True)\n",
    "dfTr = dfTraining_dict[name].query('cl3d_pubdt_passWP{0}==True'.format(args.PUWP)).copy(deep=True)\n",
    "\n",
    "del dfTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dfTr[features], dfTr[output], test_size=0.3)\n",
    "dtrain = xgb.DMatrix(data=X_train,label=y_train, feature_names=features)\n",
    "dtest = xgb.DMatrix(data=X_test,label=y_test,feature_names=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb4bo(eta, max_depth, subsample, colsample_bytree, num_trees):\n",
    "    hyperparams = {'eval_metric'      : 'logloss',\n",
    "                   'objective'        : 'binary:logistic', # objective function\n",
    "                   'nthread'          : 10, # limit number of threads\n",
    "                   'eta'              : eta, # learning rate\n",
    "                   'max_depth'        : int(round(max_depth,0)), # maximum depth of a tree\n",
    "                   'subsample'        : subsample, # fraction of events to train tree on\n",
    "                   'colsample_bytree' : colsample_bytree,# fraction of features to train tree on\n",
    "    }\n",
    "\n",
    "    booster = xgb.train(hyperparams, dtrain, num_boost_round=int(round(num_trees,0)))\n",
    "    X_train['bdt_output'] = booster.predict(dtrain)\n",
    "    X_test['bdt_output'] = booster.predict(dtest)\n",
    "    auroc_test = metrics.roc_auc_score(y_test,X_test['bdt_output'])\n",
    "    auroc_train = metrics.roc_auc_score(y_train,X_train['bdt_output'])\n",
    "\n",
    "    # this function has a maximum for abs(auroc_train-auroc_test)=0 and auroc_train=1 which is our ideal goal\n",
    "    # its shape allows to have more control on the overtraining as the function plummets as soon as x moves from 0\n",
    "    # it give a little less control on the train auroc as there the function does not plummet as much\n",
    "    return 1/10**(abs(auroc_train-auroc_test)) - 1/100**(auroc_train)\n",
    "\n",
    "hypar_bounds = {'eta'              : (0.1, 0.3), \n",
    "                'max_depth'        : (3, 7),\n",
    "                'subsample'        : (0.6, 0.8),\n",
    "                'colsample_bytree' : (0.3, 0.9),\n",
    "                'num_trees'        : (50,150)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo = BayesianOptimization(f = xgb4bo, pbounds = hypar_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "xgb_bo.maximize(init_points=10, n_iter=20, acq='ei', alpha=1e-3)\n",
    "\n",
    "end = time.time()\n",
    "print('\\nRunning time = %02dh %02dm %02ds'%((end-start)/3600, ((end-start)%3600)/60, (end-start)% 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_bo.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
